---
title: "Lake Connectivity Analysis"
author: "Chris Madsen"
date: "'r Sys.Date()'"
output:  
prettydoc::html_pretty:
    theme: material
    highlight: github
    df_print: kable
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(sf)
library(ggthemes)
library(ggspatial)
library(patchwork)
library(rmapshaper)
library(tictoc)
library(bcdata)
rm(list = ls())
```

```{r load in data}
bc = read_sf("W:/CMadsen/SpatialData/bc_simple.shp")

subw = bcdc_query_geodata('freshwater-atlas-watershed-groups') %>%
  collect()
#subw = read_sf("W:/CMadsen/SpatialData/WatershedGroups.shp")
```

```{r set parameters}
regions = subw
starting_number = 1
```

```{r background_plot}
#Set up visual output for user.
p_grid = ggplot() + 
  geom_sf(data = bc) +
  ggthemes::theme_map()

print(p_grid)
```

```{r analysis loop}
####################################
### Run analysis for each region!###
####################################

#If we're restarting the function at some point past i == 1...

if(file.exists("lakes_network_table.csv")){
  output_table = read_csv("C:/Users/CMadsen/Downloads/LocalRWork/WaterbodyConnectivity/lakes_network_table.csv")
}
 
for(i in starting_number:nrow(regions)){
  
  region = regions[i,] %>% summarise(subwatershed = WATERSHED_GROUP_ID)
    
  #Update visual "UI"
  updated_grid = p_grid + 
    geom_sf(data = region, col = "blue", fill = "lightblue", alpha = 0.5) + 
    labs(title = paste0("Region ",region$subwatershed,", ",i, " of ",nrow(regions)))
  
  print(updated_grid)
  
  #If the region is made up of a large number of separate polygons, remove any that are less than
  #1,000,000 square meters.
  if(st_geometry_type(region) == "MULTIPOLYGON"){
    region = region %>% 
      st_cast("POLYGON") %>% 
      mutate(area = as.numeric(st_area(.))) %>% 
      filter(area > 1000000) %>% 
      st_cast("MULTIPOLYGON")
  }
      
  #Load in streams and lakes for this subwatershed.
  
  print(paste0("Region ",i," - Downloading streams and lakes with bcdata package"))

  streams = bcdc_query_geodata('freshwater-atlas-stream-network') %>% filter(INTERSECTS(region)) %>% collect()
  lakes = bcdc_query_geodata('freshwater-atlas-lakes') %>% filter(INTERSECTS(region)) %>% collect()
  
  print(paste0("Region ",i," - Finished data download for this region"))
    
  streams = st_join(streams, region, st_intersects) %>% filter(!is.na(subwatershed))
  lakes = st_join(lakes, region, st_intersects) %>% filter(!is.na(subwatershed))
  
  print(paste0("Region ",i," - Cropped streams and lakes to region outline"))
  
  #Buffer streams
  tic()
  streams = st_buffer(streams, 1)
  #print("Buffering of connector shapefile complete.")
  toc()

  #Buffer polygon of interest by a little bit (3 meters) to ensure spatial overlap.
  tic()
  print(paste0("Region ",i," - Buffering polygon of interest to ensure some overlap with connectors."))
  lakes = st_buffer(lakes, dist = 3)
  toc()
  
  print(paste0("Region ",i," - Building networks."))
  
  #Prepare shapefiles for network analysis.
  lakes = lakes %>% 
    select(WATERBODY_KEY,WATERSHED_GROUP_ID,GNIS_NAME_1) %>% 
    mutate(num_components = 1)
  
  streams = streams %>% 
    select(geometry) %>% 
    st_zm()
    
  #Get number of streams / rivers connecting to lakes.
  number_connections_table = as.data.frame(st_intersects(lakes, streams)) %>% 
    as_tibble() %>% 
    group_by(row.id) %>% 
    summarise(number_connections = n())
  
  lakes$num_connections = 0
  
  lakes[number_connections_table$row.id,]$num_connections = number_connections_table$number_connections
  print(paste0("Region ",i," - Found number of connecting streams/rivers for each lake."))
    
  tic()
  print(paste0("Region ",i," - Union and cast polygons to networks..."))
  networks = st_cast(st_union(lakes %>% 
                                bind_rows(streams)), "POLYGON") %>% 
    st_as_sf()
  toc()
  
  #Find out which lakes from the cropped lake layer are 
  #in each network.
  networks = networks %>% mutate(network_number = row_number(),
                        region = i)
    
  lakes = st_join(networks, lakes, st_intersects) %>% 
    filter(!is.na(WATERSHED_GROUP_ID))
    
  #Remove networks that proved to intersect with NO lakes.
  networks = networks %>% 
    filter(network_number %in% lakes$network_number)
  
  #Save any of the networks that are within 100 meters of the subwatershed edges.
  region_edge = st_difference(region %>% summarise(), st_buffer(region %>% summarise(), -1000)) %>% 
    mutate(region_edge = T)
  
  edge_networks = st_join(networks, region_edge, st_intersects) %>% 
    filter(!is.na(region_edge))
  
  edge_networks$subwatershed = regions[i,]$WATERSHED_GROUP_ID
  
  #Just keep the portions of networks within the band of the region_edge.
  edge_networks = st_intersection(edge_networks, region_edge %>% dplyr::select(-region_edge)) %>% 
    rename(geom = x)
  
  tic()
  if(i == 1){
    sf::write_sf(edge_networks,"C:/Users/CMadsen/Downloads/LocalRWork/WaterbodyConnectivity/edge_networks.gpkg",overwrite=T)
  }else{
    all_edge_networks = read_sf("C:/Users/CMadsen/Downloads/LocalRWork/WaterbodyConnectivity/edge_networks.gpkg")
    all_edge_networks = bind_rows(all_edge_networks, edge_networks)
    sf::write_sf(all_edge_networks,"C:/Users/CMadsen/Downloads/LocalRWork/WaterbodyConnectivity/edge_networks.gpkg",overwrite=T)
  }
  print(paste0("Region ",i," - Edge networks written to disk."))
  toc()
  
  #Drop lake geometry. We're just saving the results in a tabular format.
  lakes = lakes %>% 
    st_drop_geometry() %>% 
    group_by(WATERBODY_KEY,
             WATERSHED_GROUP_ID,
             GNIS_NAME_1)
  print(paste0("Network IDs assigned to polygons of interest in region ",i))
    
  #Save the results of each loop to a table.
  lakes = lakes %>% 
    mutate(network_number = paste0(WATERSHED_GROUP_ID,"-",network_number))
  
  if(i == 1){
    output_table = lakes[0,] %>% 
      select(-num_components) %>% 
      ungroup() %>% 
      mutate(regions_completed = i)
  }
  
  output_table = bind_rows(output_table, lakes %>% 
                             dplyr::select(-num_components) %>% 
                             ungroup()) %>% 
    mutate(regions_completed = i)
  
  write.csv(output_table, 
              paste0("C:/Users/CMadsen/Downloads/LocalRWork/WaterbodyConnectivity/lakes_network_table.csv"),
              row.names = F)
  
  print(paste0("Lake network table updated. Number of non-NA lakes is now: ", nrow(output_table %>% filter(!is.na(network_number)))))
    
  print(paste0("Networks found for region ",i))
}

```


```{r}
### Edge Networks ###

# If we're skipping the above section, as it's already done, load in the output_table.

output_table = read_csv("C:/Users/CMadsen/Downloads/LocalRWork/WaterbodyConnectivity/lakes_network_table.csv")
all_edge_networks = read_sf('edge_networks.gpkg')

#At this point, no networks should span multiple subwatersheds...
output_table %>% 
  group_by(network_number) %>% 
  count(WATERSHED_GROUP_ID, sort = T)

# Some networks abut the boundaries between subwatersheds. These networks may, in reality, be joined.

#First, just to be generous, buffer the edge networks by 2 more meters (total buffer now 3m)
all_edge_networks_buffered = st_buffer(all_edge_networks, dist = 2)

#Find which rows overlap which other rows from our all_edge_networks_buffered object.
overlap_matrix = st_intersects(all_edge_networks_buffered)

overlap_table = overlap_matrix %>% 
  as.data.frame() %>% 
  as_tibble() %>% 
  filter(row.id != col.id)


### REMOVE AFTER TRIAL ###
# ggplot() + 
#   geom_sf(data = output_table %>% filter(network_number == "179-1"), col='red',fill='red') +
#   geom_sf(data = output_table %>% filter(network_number == "8-1"), col='blue',fill='blue')

overlaps_to_add_to_output_table = cbind(all_edge_networks_buffered %>% 
  st_drop_geometry() %>% 
  slice(overlap_table$row.id) %>% 
  summarise(network_number = paste0(subwatershed,"-",network_number)), 
  all_edge_networks_buffered %>% 
  st_drop_geometry() %>% 
  slice(overlap_table$col.id) %>% 
  summarise(network_number_right = paste0(subwatershed,"-",network_number))
) %>% 
  as_tibble() %>% 
  #Drop any rows that are of networks in the same subwatershed.
  filter(str_extract(network_number,"^[0-9]*(?=-)") != str_extract(network_number_right,"^[0-9]*(?=-)"))
  
### REMOVE AFTER TRIAL ###
# ggplot() + geom_sf(data = all_edge_networks %>% filter(paste0(subwatershed,"-",network_number) %in% c("41-1","228-128")), aes(col = region, fill = region))
#The edge network overlaps are being correctly identified. Could the masking to the ~100 m subwatershed boundaries be merging networks that shouldn't be one? Unlikely...

overlaps_to_add_to_output_table = overlaps_to_add_to_output_table %>% 
  group_by(network_number) %>% 
  summarise(network_number_right = paste0(network_number_right, collapse = ", ")) %>% 
  separate(network_number_right, sep = ", ", into = c(paste0("network_number_right_",rep(1:7))))
#Note: I've double-checked the output of this tabel - the subwatersheds that it claims to be linked together make sense! Hurray!
```


```{r}
#If continuing from above, use this line:
lake_networks = output_table
#Else, read in the data from disk.
#lake_networks = read_csv('lakes_network_table.csv')

#Add a flag for which lakes actually need to have their networks merged.
lake_networks = lake_networks %>% 
  left_join(overlaps_to_add_to_output_table)

### REMOVE THE FOLLOWING LINE AFTER TESTING! ### 
# lake_networks = lake_networks %>% 
#   filter(WATERSHED_GROUP_ID == 1)

#The network IDs are wonky... because network id's were determined using row_number(), there are many missing numbers. 
#The following table lists the number of unique networks per subwatershed, and gives us a cumsum for each
#watershed that can be used as a network id correction factor.

networks_per_subw = lake_networks %>% 
  group_by(WATERSHED_GROUP_ID) %>% 
  summarise(number_networks_per_subw = length(unique(network_number))) %>% 
  mutate(network_correction_factor = lag(number_networks_per_subw)) %>% 
  mutate(network_correction_factor = replace_na(network_correction_factor, 0)) %>% 
  mutate(network_correction_factor = cumsum(network_correction_factor))

lake_networks = lake_networks %>%
  ungroup() %>% 
  mutate(network_number_old = network_number) %>% 
  mutate(network_number = as.numeric(str_remove(network_number, "[0-9]*-"))) %>% 
  group_by(WATERSHED_GROUP_ID, network_number) %>% 
  mutate(network_number_new = cur_group_id()) %>% 
  select(network_number,network_number_new,everything()) %>% 
  #Add in the table showing the number of unique components in each subwatershed.
  left_join(networks_per_subw) %>% 
  mutate(network_number = network_number_new + network_correction_factor) %>% 
  select(-network_number_new) %>% 
  ungroup()
#The above code seems to work without a hitch.

#Which network numbers need to be unified?
which(!is.na(lake_networks$network_number_right_1)) %>% 
  as_tibble()
#244,590 lakes need to have their networks adjusted!

network_number_old_to_new = lake_networks %>% 
  dplyr::select(network_number,network_number_old,network_number_right_1) %>% 
  distinct() %>% 
  filter(!is.na(network_number_right_1)) %>% 
  dplyr::select(-network_number_right_1)

# We need to look across the 1 to 8 columns that contain the (old) network IDs of overlapping edge networks.
# With this, we can replace the old IDs of those networks with the new network IDs.
# This table output lists, for overlapping edge networks, the network number, the list of networks in the overlapping segment (NOTE: can be multiple overlaps that include a given network!), and what the lowest network in that overlapping segment is.
lake_network_replace_table = lake_networks %>% 
  dplyr::select(network_number_old,starts_with("network_number_right_")) %>% 
  distinct() %>% 
  filter(!is.na(network_number_right_1)) %>% 
  left_join(network_number_old_to_new) %>% 
  mutate(network_number_old = network_number) %>% 
  dplyr::select(-network_number) %>% 
  left_join(network_number_old_to_new %>% rename(network_number_right_1 = network_number_old)) %>% 
  mutate(network_number_right_1 = network_number) %>% 
  dplyr::select(-network_number) %>% 
  left_join(network_number_old_to_new %>% rename(network_number_right_2 = network_number_old)) %>% 
  mutate(network_number_right_2 = network_number) %>% 
  dplyr::select(-network_number) %>% 
  left_join(network_number_old_to_new %>% rename(network_number_right_3 = network_number_old)) %>% 
  mutate(network_number_right_3 = network_number) %>% 
  dplyr::select(-network_number) %>% 
  left_join(network_number_old_to_new %>% rename(network_number_right_4 = network_number_old)) %>% 
  mutate(network_number_right_4 = network_number) %>% 
  dplyr::select(-network_number) %>% 
  left_join(network_number_old_to_new %>% rename(network_number_right_5 = network_number_old)) %>% 
  mutate(network_number_right_5 = network_number) %>% 
  dplyr::select(-network_number) %>% 
  left_join(network_number_old_to_new %>% rename(network_number_right_6 = network_number_old)) %>% 
  mutate(network_number_right_6 = network_number) %>% 
  dplyr::select(-network_number) %>% 
  left_join(network_number_old_to_new %>% rename(network_number_right_7 = network_number_old)) %>% 
  mutate(network_number_right_7 = network_number) %>% 
  dplyr::select(-network_number) %>% 
  #Now each column has had its network's ID updated to the cross-subwatershed numbering system.
  rename(network_number = network_number_old) %>% 
  pivot_longer(-network_number) %>% 
  filter(!is.na(value)) %>% 
  group_by(network_number) %>% 
  summarise(networks_to_be_grouped = paste0(value, collapse = ", "),
            lowest_network_in_group = min(c(network_number,value), na.rm=T)) %>% 
  mutate(networks_to_be_grouped = paste0(network_number, ", ", networks_to_be_grouped))

lake_networks = lake_networks %>% 
  dplyr::select(-starts_with("network_number_right_")) %>% 
  left_join(lake_network_replace_table) %>% 
  #mutate(networks_to_be_grouped = str_extract_all(networks_to_be_grouped, "[0-9]")) %>% 
  mutate(network_number = case_when(
    #If there are no other networks in this group to be merged, keep network number as is.
    is.na(networks_to_be_grouped) ~ network_number,
    #If the 'networks_to_be_grouped' field isn't NA, use the lowest network ID to replace this row's network_number.
    T ~ lowest_network_in_group
  )) %>% 
  dplyr::select(-regions_completed,
                -network_number_old,
                -network_correction_factor,
                -networks_to_be_grouped,
                -lowest_network_in_group)

#Also, some lakes span more than one subwatershed (e.g. Williston Lake). 309 rows, or 28 lakes total.
#The networks that these lakes are part of can be joined!
border_lakes = lake_networks %>% 
  mutate(identifier = paste0(WATERBODY_KEY,GNIS_NAME_1)) %>% 
  filter(identifier %in% all_of(lake_networks %>%
                                  filter(!is.na(GNIS_NAME_1)) %>% 
                                  mutate(lake_id = paste0(WATERBODY_KEY,GNIS_NAME_1)) %>%
                                  filter(duplicated(lake_id)) %>%
                                  summarise(identifier = paste0(WATERBODY_KEY,GNIS_NAME_1)) %>% 
                                  distinct() %>% 
                                  pull(identifier))) %>% 
  group_by(WATERBODY_KEY,GNIS_NAME_1) %>%
  mutate(lowest_network_id = min(network_number),
         networks_to_merge = paste0(unique(network_number), collapse = ",")) %>%
  ungroup() %>% 
  filter(str_detect(networks_to_merge, ","))

lake_networks = lake_networks %>%
  left_join(border_lakes %>%
              dplyr::select(network_number,
                            networks_to_merge,lowest_network_id) %>%
              distinct()) %>%
  distinct() %>% 
  mutate(network_number = case_when(
    #If there's nothing in the 'lowest_network_id' field, retain the number that was in 'network_number'!
    is.na(lowest_network_id) ~ network_number,
    T ~ lowest_network_id
  )) %>% 
  dplyr::select(-region,-networks_to_merge,-lowest_network_id)
```

We now have a table the includes every lake in BC, with an added field that identifies the component network that each lake is a part of. The networks were initially delineated by connecting all lakes, streams and rivers within 4 meters of each other (streams were buffered by 1 m, lakes by 3 m). These networks were buffered an additional 2 meters, then combined with intersecting networks of the same or other subwatersheds (more linkages within a single subwatershed possible in this step). Finally, some lakes straddle the boundaries between subwatersheds - we found all such lakes THAT ARE NAMED (for safety's sake in terms of merging... not to incorrectly merge unnamed lakes) and that share a waterbody_key (quite reliable identifier for lake polygons that are separate but that refer to the same lake in the real world) and assigned whatever the lowest network ID of each set of matching lake polygons was to ALL of the lakes in those networks (i.e. the lake functions as a connector for the networks).

```{r output results}
write.csv(lake_networks, "C:/Users/CMadsen/Downloads/LocalRWork/output/provincial_waterbody_networks.csv", row.names = F)
```
