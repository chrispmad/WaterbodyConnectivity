---
title: "Lake Connectivity Analysis"
author: "Chris Madsen"
date: "'r Sys.Date()'"
output:  
prettydoc::html_pretty:
    theme: material
    highlight: github
    df_print: kable
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(sf)
library(ggthemes)
library(ggspatial)
library(patchwork)
library(rmapshaper)
library(tictoc)
library(bcdata)
rm(list = ls())
```

```{r load in data}
bc = read_sf("W:/CMadsen/SpatialData/bc_simple.shp")

subw = bcdc_query_geodata('freshwater-atlas-watershed-groups') %>%
  collect()
#subw = read_sf("W:/CMadsen/SpatialData/WatershedGroups.shp")
```

```{r set parameters}
regions = subw
starting_number = 1
```

```{r background_plot}
#Set up visual output for user.
p_grid = ggplot() + 
  geom_sf(data = bc) +
  ggthemes::theme_map()

print(p_grid)
```

```{r analysis loop}
####################################
### Run analysis for each region!###
####################################

#If we're restarting the function at some point past i == 1...

if(file.exists("lakes_network_table.csv")){
  output_table = read_csv("C:/Users/CMadsen/Downloads/LocalRWork/WaterbodyConnectivity/lakes_network_table.csv")
}
 
for(i in starting_number:nrow(regions)){
  
  region = regions[i,] %>% summarise(subwatershed = WATERSHED_GROUP_ID)
    
  #Update visual "UI"
  updated_grid = p_grid + 
    geom_sf(data = region, col = "blue", fill = "lightblue", alpha = 0.5) + 
    labs(title = paste0("Region ",region$subwatershed,", ",i, " of ",nrow(regions)))
  
  print(updated_grid)
  
  #If the region is made up of a large number of separate polygons, remove any that are less than
  #1,000,000 square meters.
  if(st_geometry_type(region) == "MULTIPOLYGON"){
    region = region %>% 
      st_cast("POLYGON") %>% 
      mutate(area = as.numeric(st_area(.))) %>% 
      filter(area > 1000000) %>% 
      st_cast("MULTIPOLYGON")
  }
      
  #Load in streams and lakes for this subwatershed.
  
  print(paste0("Region ",i," - Downloading streams and lakes with bcdata package"))

  streams = bcdc_query_geodata('freshwater-atlas-stream-network') %>% filter(INTERSECTS(region)) %>% collect()
  lakes = bcdc_query_geodata('freshwater-atlas-lakes') %>% filter(INTERSECTS(region)) %>% collect()
  
  print(paste0("Region ",i," - Finished data download for this region"))
    
  streams = st_join(streams, region, st_intersects) %>% filter(!is.na(subwatershed))
  lakes = st_join(lakes, region, st_intersects) %>% filter(!is.na(subwatershed))
  
  print(paste0("Region ",i," - Cropped streams and lakes to region outline"))
  
  #Buffer streams
  tic()
  streams = st_buffer(streams, 1)
  #print("Buffering of connector shapefile complete.")
  toc()

  #Buffer polygon of interest by a little bit (3 meters) to ensure spatial overlap.
  tic()
  print(paste0("Region ",i," - Buffering polygon of interest to ensure some overlap with connectors."))
  lakes = st_buffer(lakes, dist = 3)
  toc()
  
  print(paste0("Region ",i," - Building networks."))
  
  #Prepare shapefiles for network analysis.
  lakes = lakes %>% 
    select(WATERBODY_KEY,WATERSHED_GROUP_ID,GNIS_NAME_1) %>% 
    mutate(num_components = 1)
  
  streams = streams %>% 
    select(geometry) %>% 
    st_zm()
    
  #Get number of streams / rivers connecting to lakes.
  number_connections_table = as.data.frame(st_intersects(lakes, streams)) %>% 
    as_tibble() %>% 
    group_by(row.id) %>% 
    summarise(number_connections = n())
  
  lakes$num_connections = 0
  
  lakes[number_connections_table$row.id,]$num_connections = number_connections_table$number_connections
  print(paste0("Region ",i," - Found number of connecting streams/rivers for each lake."))
    
  tic()
  print(paste0("Region ",i," - Union and cast polygons to networks..."))
  networks = st_cast(st_union(lakes %>% 
                                bind_rows(streams)), "POLYGON") %>% 
    st_as_sf()
  toc()
  
  #Find out which lakes from the cropped lake layer are 
  #in each network.
  networks = networks %>% mutate(network_number = row_number(),
                        region = i)
    
  lakes = st_join(networks, lakes, st_intersects) %>% 
    filter(!is.na(WATERSHED_GROUP_ID))
    
  #Remove networks that proved to intersect with NO lakes.
  networks = networks %>% 
    filter(network_number %in% lakes$network_number)
  
  #Save any of the networks that are within 100 meters of the subwatershed edges.
  region_edge = st_difference(region %>% summarise(), st_buffer(region %>% summarise(), -1000)) %>% 
    mutate(region_edge = T)
  
  edge_networks = st_join(networks, region_edge, st_intersects) %>% 
    filter(!is.na(region_edge))
  
  edge_networks$subwatershed = regions[i,]$WATERSHED_GROUP_ID
  
  #Just keep the portions of networks within the band of the region_edge.
  edge_networks = st_intersection(edge_networks, region_edge %>% dplyr::select(-region_edge)) %>% 
    rename(geom = x)
  
  tic()
  if(i == 1){
    sf::write_sf(edge_networks,"C:/Users/CMadsen/Downloads/LocalRWork/WaterbodyConnectivity/edge_networks.gpkg",overwrite=T)
  }else{
    all_edge_networks = read_sf("C:/Users/CMadsen/Downloads/LocalRWork/WaterbodyConnectivity/edge_networks.gpkg")
    all_edge_networks = bind_rows(all_edge_networks, edge_networks)
    sf::write_sf(all_edge_networks,"C:/Users/CMadsen/Downloads/LocalRWork/WaterbodyConnectivity/edge_networks.gpkg",overwrite=T)
  }
  print(paste0("Region ",i," - Edge networks written to disk."))
  toc()
  
  #Drop lake geometry. We're just saving the results in a tabular format.
  lakes = lakes %>% 
    st_drop_geometry() %>% 
    group_by(WATERBODY_KEY,
             WATERSHED_GROUP_ID,
             GNIS_NAME_1)
  print(paste0("Network IDs assigned to polygons of interest in region ",i))
    
  #Save the results of each loop to a table.
  lakes = lakes %>% 
    mutate(network_number = paste0(WATERSHED_GROUP_ID,"-",network_number))
  
  if(i == 1){
    output_table = lakes[0,] %>% 
      select(-num_components) %>% 
      ungroup() %>% 
      mutate(regions_completed = i)
  }
  
  output_table = bind_rows(output_table, lakes %>% 
                             dplyr::select(-num_components) %>% 
                             ungroup()) %>% 
    mutate(regions_completed = i)
  
  write.csv(output_table, 
              paste0("C:/Users/CMadsen/Downloads/LocalRWork/WaterbodyConnectivity/lakes_network_table.csv"),
              row.names = F)
  
  print(paste0("Lake network table updated. Number of non-NA lakes is now: ", nrow(output_table %>% filter(!is.na(network_number)))))
    
  print(paste0("Networks found for region ",i))
}

```

```{r}
##Visualize a given subwatershed...
# subw100_lakes = bcdc_query_geodata('freshwater-atlas-lakes') %>% 
#   filter(WATERSHED_GROUP_ID == 100) %>% 
#   collect()
# 
# subw100_lakes = subw100_lakes %>% 
#   left_join(lake_networks %>% dplyr::select(WATERBODY_KEY,WATERSHED_GROUP_ID,GNIS_NAME_1,network_number))
# 
# sf::write_sf(subw100_lakes, "W:/CMadsen/SpatialData/Subw_100_lakes_networked.gpkg")
# 
# ggplot() + 
#   geom_sf(data = subw[subw$WATERSHED_GROUP_ID == 100,]) + 
#   geom_sf(data = subw100_lakes, aes(fill = network_number))
```

```{r}
lake_networks = output_table

#The network IDs are wonky... because network id's were determined using row_number(), there are many missing numbers. #The following table lists the number of unique networks per subwatershed, and gives us a cumsum for each
#watershed that can be used as a network id correction factor.

networks_per_subw = lake_networks %>% 
  group_by(WATERSHED_GROUP_ID) %>% 
  summarise(number_networks_per_subw = length(unique(network_number))) %>% 
  mutate(network_correction_factor = lag(number_networks_per_subw)) %>% 
  mutate(network_correction_factor = replace_na(network_correction_factor, 0)) %>% 
  mutate(network_correction_factor = cumsum(network_correction_factor))

lake_networks = lake_networks %>% 
  mutate(network_number = as.numeric(str_remove(network_number, "[0-9]*-"))) %>% 
  arrange(network_number) %>%
  mutate(network_number = as.factor(network_number)) %>% 
  mutate(network_number = fct_infreq(network_number)) %>% 
  mutate(network_number = as.numeric(network_number)) %>%
  #Add in the table showing the number of unique components in each subwatershed.
  left_join(networks_per_subw) %>% 
  mutate(network_number = network_number + network_correction_factor)

#Also, some lakes span more than one subwatershed (e.g. Williston Lake). 309 rows, or 28 lakes total.
#The networks that these lakes are part of can be joined!
border_lakes = lake_networks %>% 
  mutate(lake_id = paste0(WATERBODY_KEY,GNIS_NAME_1)) %>% 
  filter(duplicated(lake_id)) %>% 
  dplyr::select(network_number,WATERBODY_KEY,GNIS_NAME_1) %>% 
  distinct() %>% 
  group_by(WATERBODY_KEY,GNIS_NAME_1) %>% 
  mutate(lowest_network_id = min(network_number),
         networks_to_merge = paste0(network_number, collapse = ",")) %>% 
  ungroup()

lake_networks = lake_networks %>% 
  left_join(border_lakes %>% 
              dplyr::select(network_number,networks_to_merge,lowest_network_id)) %>% 
  mutate(network_number = case_when(
    str_detect(networks_to_merge,as.character(network_number)) ~ lowest_network_id,
    T ~ network_number
  ))
```

```{r}
# #Let's try making a graph to represent the networks in a given subwatershed.
# library(tidygraph)
# library(ggraph)
#   
# graph_df = lake_networks %>% 
#   filter(WATERSHED_GROUP_ID == 102, region == 12) %>% 
#   rename(wb_name = GNIS_NAME_1) %>% 
#   group_by(WATERBODY_KEY) %>% 
#   mutate(WATERBODY_KEY = cur_group_id()) %>% 
#   ungroup() %>% 
#   mutate(wb_name = ifelse(is.na(wb_name), as.character(WATERBODY_KEY), wb_name)) %>% 
#   dplyr::select(wb_name,network_number,num_connections) %>% 
#   distinct() %>% 
#   add_count(network_number) %>% 
#   #filter(n > 2) %>% 
#   select(-n) %>% 
#   arrange(desc(num_connections))
#   
# #We could use the connectivity I measured in the loop above to guide the number of (arbitrary) linkages drawn.
# edges = graph_df %>% 
#   # uncount(num_connections) %>% 
#   # left_join(graph_df) %>% 
#   rename(from = wb_name) %>% 
#   group_by(from) %>% 
#   mutate(to = case_when(
#     num_connections > 1 ~ list(sample(graph_df[graph_df$wb_name != from,]$wb_name,num_connections,replace=F)),
#     T ~ list(from))) %>% 
#   ungroup() %>% 
#   select(from, to) %>% 
#   unnest_longer(to)
# 
# my_tbl_graph = tbl_graph(edges = edges, nodes = graph_df,
#           directed = F)
# 
# my_tbl_graph %>% 
#   ggraph(layout = 'kk') + 
#   #geom_edge_link(aes(alpha = ..index..), show.legend = FALSE) + 
#   geom_node_point(aes(colour = as.factor(network_number), size = log10(num_connections))) + 
#   theme_graph() + 
#   scale_color_brewer(palette = "Dark2", guide = "none") + 
#   scale_size_continuous(guide = "none") +
#   labs(col = "Group")
```

```{r}
#Just a basic ggplot to show how large some of the larger networks are.

```


```{r}
#To stitch together any networks that SHOULD be a single network but were
#split apart by subwatershed boundaries, we can first find all networks that come close to subwatershed boundaries.

#First, which lakes are within, say, 1 kilometer of any subwatershed borders?
# subw_neg = st_buffer(subw, -100)
# subw_edge = st_difference(subw, region_negative)

# for(i in 1:nrow(subw)){
#   region = subw[i,]

  #If the region is made up of a large number of separate polygons, remove any that are less than
  #1,000,000 square meters.
  if(st_geometry_type(region) == "MULTIPOLYGON"){
    region = region %>%
      st_cast("POLYGON") %>%
      mutate(area = as.numeric(st_area(.))) %>%
      filter(area > 1000000) %>%
      st_cast("MULTIPOLYGON")
  }

  #Do a negative buffer of 100 meters around the subwatershed i.
  region_negative = st_buffer(region, -100)
  region_edge = st_difference(region, region_negative)

  #Get lakes that are inside this subwatershed.
  border_lakes = bcdc_query_geodata('freshwater-atlas-lakes') %>%
    filter(WATERSHED_GROUP_ID == region$WATERSHED_GROUP_ID) %>%
    collect() %>%
    st_join(region_edge %>% dplyr::select(WATERSHED_GROUP_NAME), st_intersects) %>%
    filter(!is.na(WATERSHED_GROUP_NAME))

  ggplot() + geom_sf(data = border_lakes)
}

```




